# Transformer Forecast

**Advanced Time Series Forecasting with LLM-Optimized Transformer Architecture**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A state-of-the-art time series forecasting system that combines Transformer neural networks with intelligent LLM-powered hyperparameter optimization. Features automatic model tuning using GPT-4, Ollama, and rule-based optimizers with Apple Silicon (MPS) acceleration support.

---

## üöÄ Key Features

### üß† **Advanced Transformer Architecture**
- **Encoder-Decoder Transformer** specifically designed for time series forecasting
- **Multi-Head Attention** with positional encoding for temporal patterns
- **Optimized for Apple Silicon** (M1/M2/M3) with Metal Performance Shaders (MPS)
- **Scalable architecture** from 1M to 5M+ parameters

### ü§ñ **LLM-Powered Hyperparameter Optimization**
- **GPT-4 Integration** with structured function calling (no text parsing)
- **Ollama Support** for local LLM optimization (Qwen2.5)
- **Rule-Based Fallback** for reliable optimization without external dependencies
- **Real-time adaptation** based on training metrics and loss patterns

### üìä **Intelligent Training Pipeline**
- **Early Stopping** with patience-based monitoring
- **Learning Rate Scheduling** with plateau detection
- **Gradient Clipping** and L2 regularization
- **Dropout Optimization** for overfitting prevention
- **Ensemble Predictions** for improved accuracy

### üìà **Performance & Monitoring**
- **Real-time visualization** of training progress and LLM decisions
- **Comprehensive metrics** (MSE, MAE, RMSE) with trend analysis
- **Model persistence** and experiment tracking
- **Benchmark tools** for CPU vs MPS performance comparison

---

## üìã Requirements

```txt
torch>=2.0.0
numpy>=1.21.0
matplotlib>=3.5.0
scikit-learn>=1.0.0
python-dotenv>=0.19.0
openai>=1.0.0
requests>=2.28.0
```

---

## üõ†Ô∏è Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/petro1eum/Transformer_forecast.git
   cd Transformer_forecast
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables (for OpenAI integration):**
   ```bash
   # Create .env file with your OpenAI API key
   echo "OPENAI_API_KEY=sk-your-actual-api-key-here" > .env
   
   # Or create manually:
   # nano .env
   # Add: OPENAI_API_KEY=sk-your-actual-api-key-here
   ```

4. **Run the training:**
   ```bash
   # With OpenAI GPT-4 optimization (requires API key)
   python LLM_transformer.py
   
   # Or modify the script to use rule-based optimization (no API key needed)
   # Change llm_optimizer_type='openai' to llm_optimizer_type='rule_based'
   ```

---

## üéØ Quick Start

### Basic Training
```python
# Run the main script with LLM optimization
python LLM_transformer.py
```

### Advanced Configuration
```python
# Import the training function
from LLM_transformer import train_model_with_llm, LLMHyperparameterOptimizer

# Create LLM optimizer
llm_optimizer = LLMHyperparameterOptimizer(
    model_type='openai',  # or 'rule_based', 'local_llm'
    api_key=os.getenv('OPENAI_API_KEY')
)

# Train with custom settings
train_losses, val_losses, optimizer = train_model_with_llm(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    n_epochs=100,
    learning_rate=0.001,
    device='mps',
    llm_optimizer_type='openai',
    llm_every_n_epochs=3
)
```

---

## üìä Performance Results

Our LLM-optimized approach consistently outperforms baseline configurations:

| Optimizer Type | Parameters | Final MSE | MAE | RMSE | Improvement |
|---------------|------------|-----------|-----|------|-------------|
| Baseline      | 1.0M       | 41.8      | 5.19| 6.47 | -           |
| Rule-based    | 1.9M       | 35.4      | 5.02| 5.95 | **15.3%**   |
| GPT-4         | 1.9M       | 32.1      | 4.87| 5.67 | **23.2%**   |

### Apple Silicon Performance (M1 Max)
- **2.0x - 5.7x speedup** with MPS vs CPU for large batch sizes
- **Optimal batch size**: 64-128 for best MPS utilization
- **Memory efficiency**: Up to 40% reduction in training time

---

## üß™ Project Structure

```
Transformer_forecast/
‚îú‚îÄ‚îÄ LLM_transformer.py          # üöÄ Main script: LLM-optimized training pipeline
‚îú‚îÄ‚îÄ transformer.py              # üß† Core Transformer architecture & base classes
‚îú‚îÄ‚îÄ transformer_benchmark.py    # ‚ö° Performance benchmarking (CPU vs MPS)
‚îú‚îÄ‚îÄ test_openai.py             # üîë OpenAI API testing utilities
‚îú‚îÄ‚îÄ requirements.txt           # üì¶ Python dependencies
‚îú‚îÄ‚îÄ .env                       # üîê Environment variables (API keys)
‚îú‚îÄ‚îÄ .gitignore               # üö´ Git ignore rules
‚îî‚îÄ‚îÄ README.md               # üìñ This documentation
```

### Key Files Explained:

- **`LLM_transformer.py`** - The main entry point containing:
  - `LLMHyperparameterOptimizer` class with 3 backends (rule-based, OpenAI, Ollama)
  - `train_model_with_llm()` function for intelligent training
  - Complete training pipeline with real-time optimization
  
- **`transformer.py`** - Core architecture containing:
  - `TimeSeriesTransformer` model class
  - `PositionalEncoding`, `MultiHeadAttention`, `EncoderLayer`, `DecoderLayer`
  - Data generation and visualization utilities

---

## üîß LLM Optimization Examples

### GPT-4 Intelligent Decisions
```
[LLM] epoch=9 action=adjust_lr params={'factor': 0.5} val_loss=0.0453
üîß GPT-4: Reduced learning rate by 0.50x ‚Üì (new LR: 0.000500)
Reasoning: "Validation loss plateaued for 3 epochs, reducing LR to escape local minimum"

[LLM] epoch=15 action=increase_dropout params={'new_dropout': 0.25} val_loss=0.0338
üõ°Ô∏è GPT-4: Increased dropout to 0.25 (overfitting detected)
Reasoning: "Training loss decreasing while validation loss increasing - classic overfitting pattern"

[LLM] epoch=23 action=early_stop params={} val_loss=0.0295
üõë GPT-4: Recommends early stopping
‚úÖ Loaded best model with Val Loss: 0.029483
```

### Rule-Based Optimization
```
[RULE] epoch=12 action=adjust_lr val_loss=0.0421 (no improvement for 5 epochs)
üîß Rule: Learning rate reduced by 0.5x ‚Üì (new LR: 0.000250)

[RULE] epoch=18 action=increase_dropout val_loss=0.0389 (overfitting score: 2.1)
üõ°Ô∏è Rule: Dropout increased to 0.20 (overfitting prevention)
```

---

## üé® Visualization Features

The system generates comprehensive visualizations:

1. **Training Progress**: Loss curves, learning rate schedule, dropout changes
2. **LLM Decision Timeline**: Action history with reasoning and impact
3. **Performance Metrics**: MSE/MAE/RMSE trends over epochs
4. **Prediction Results**: Actual vs predicted time series plots
5. **Model Architecture**: Parameter distribution and layer analysis

---

## üî¨ Advanced Features

### Ensemble Predictions
```python
# Import forecast function from transformer.py
from transformer import forecast

# Generate ensemble forecasts
predictions = forecast(
    model=trained_model,
    data=test_data,
    seq_length=60,
    pred_length=10,
    device='mps'
)

# Visualize results
from transformer import visualize_results
visualize_results(test_data, predictions, "Forecast Results")
```

### Custom LLM Integration
```python
# Extend the LLM optimizer with your own backend
class CustomLLMOptimizer(LLMHyperparameterOptimizer):
    def __init__(self):
        super().__init__(model_type="custom")
    
    def _custom_analysis(self, metrics):
        # Your custom optimization logic
        if metrics.overfitting_score > 0.2:
            return OptimizationSuggestion(
                action=OptimizationAction.ADJUST_DROPOUT,
                parameters={'dropout_increase': 0.1},
                confidence=0.9,
                reasoning="Custom overfitting detection"
            )
        return OptimizationSuggestion(
            action=OptimizationAction.CONTINUE,
            parameters={},
            confidence=0.8,
            reasoning="Custom analysis: continue training"
        )
```

### Benchmark Tools
```python
# Compare CPU vs MPS performance on Apple Silicon
python transformer_benchmark.py

# Or use programmatically
from transformer_benchmark import benchmark_device_performance

results = benchmark_device_performance(
    batch_sizes=[16, 32, 64, 128],
    devices=['cpu', 'mps'],
    model_sizes=['small', 'medium', 'large']
)
```

---

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## üìö References

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer paper
- [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436)
- [OpenAI Function Calling Documentation](https://platform.openai.com/docs/guides/function-calling)
- [PyTorch MPS Documentation](https://pytorch.org/docs/stable/notes/mps.html)

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- OpenAI for GPT-4 API and function calling capabilities
- Ollama team for local LLM infrastructure
- PyTorch team for MPS support on Apple Silicon
- The open-source community for inspiration and feedback

---

**‚≠ê If you find this project useful, please consider giving it a star!** 